{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/gibranfp/CursoAprendizajeProfundo/blob/master/notebooks/1c_retropropagacion.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V83__FrBij1f"
   },
   "source": [
    "# Retropropagación\n",
    "\n",
    "En este *notebook* programaremos con NumPy una red neuronal densa y la entrenaremos para aproximar la operación XOR usando del gradiente descedente con el algoritmo de retropropagación. Recordemos que la operación XOR ($\\otimes$) está de la siguiente manera:\n",
    "\n",
    "| $x_1$ | $x_2$ | $y$\n",
    "| ------------- |:-------------:| -----:|\n",
    "|0 |0 |0|\n",
    "|0 |1 |1|\n",
    "|1 |0 |1|\n",
    "|1 |1 |0|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "xSlnjW4Oi-FP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-iAUmKI5jNuX"
   },
   "source": [
    "Nuestra red neuronal densa está compuesta por una capa de 2 entradas ($x_1$ y $x_2$), una capa oculta con 10 neuronas con función de activación sigmoide y una capa de salida con una sola neurona con función de activación sigmoide. Esta función de activación se define como:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WYhT3i68jf6x"
   },
   "outputs": [],
   "source": [
    "def sigmoide(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qx6SyrPhWBrw"
   },
   "source": [
    "La función sigmoide tiene una derivada que está expresada en términos de la misma función, esto es, \n",
    "\n",
    "$$\n",
    "\\frac{\\partial \\sigma (z)}{\\partial z} = \\sigma(z) (1 - \\sigma(z))\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mJxvxKeAjn24"
   },
   "outputs": [],
   "source": [
    "def derivada_sigmoide(x):\n",
    "    return np.multiply(sigmoide(x), (1.0 - sigmoide(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4WxI8FfLXKHv"
   },
   "source": [
    "Podemos ver la operación XOR como una tarea de clasificación binaria a partir de 2 entradas. Por lo tanto, usaremos la función de pérdida de entropía cruzada binaria:\n",
    "\n",
    "$$\n",
    "ECB(\\mathbf{y}, \\mathbf{\\hat{y}})  = -\\sum_{i=1}^N \\left[ y^{(i)} \\log \\hat{y}^{(i)} + (1 - y^{(i)}) \\log (1 - \\hat{y}^{(i)}) \\right]\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "gDjlmpAQjR3X"
   },
   "outputs": [],
   "source": [
    "def entropia_cruzada_binaria(y, p):\n",
    "    p[p == 0] = np.nextafter(0., 1.)\n",
    "    p[p == 1] = np.nextafter(1., 0.)\n",
    "    return -(np.log(p[y == 1]).sum() + np.log(1 - p[y == 0]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k8nMdK-RYWMS"
   },
   "source": [
    "Asimismo, calcularemos la exactitud para medir el rendimiento del modelo aprendido por la red neuronal densa:\n",
    "\n",
    "$$\n",
    "exactitud = \\frac{correctos}{total}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "8wxvZq10jIM3"
   },
   "outputs": [],
   "source": [
    "def exactitud(y, y_predicha):\n",
    "    return (y == y_predicha).mean() * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p02hAdUFZNLL"
   },
   "source": [
    "Ahora, definimos la función que propaga hacia adelante una entrada $\\mathbf{x}^{i}$. Como la red está compuesta de 2 capas densas (1 oculta y 1 de salida), tenemos 2 matrices de pesos con sus correspondientes vectores de sesgos $\\{\\mathbf{W}^{\\{1\\}}, \\mathbf{b}^{\\{1\\}}\\}$ y $\\{\\mathbf{W}^{\\{2\\}}, \\mathbf{b}^{\\{2\\}}\\}$ de la capa oculta y la capa de salida respectivamente. Así, podemos llevar a cabo la propagación hacia adelante en esta red de la siguiente manera:\n",
    "\n",
    "$$\n",
    "\t\\begin{split}\n",
    "\t\t\t\t\\mathbf{a}^{\\{1\\}} & =  \\mathbf{x}^{(i)} \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{2\\}} & =  \\mathbf{W}^{\\{1\\}} \\cdot \\mathbf{a}^{\\{1\\}} + \\mathbf{b}^{\\{1\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{2\\}} & =  \\sigma(\\mathbf{z}^{\\{2\\}}) \\\\\n",
    "\t\t\t\t\\mathbf{z}^{\\{3\\}} & =  \\mathbf{W}^{\\{2\\}} \\cdot \\mathbf{a}^{\\{2\\}}  + \\mathbf{b}^{\\{2\\}}\\\\\n",
    "\t\t\t\t\\mathbf{a}^{\\{3\\}} & =  \\sigma(\\mathbf{z}^{\\{3\\}})\\\\\n",
    "\t\t\t\t\\hat{y}^{(i)} & =  \\mathbf{a}^{\\{3\\}}\n",
    "\t\t\t\\end{split}\n",
    "      $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "lAsEk-zajvpX"
   },
   "outputs": [],
   "source": [
    "def hacia_adelante(x, W1, b1, W2, b2):\n",
    "    z2 = np.dot(W1.T, x[:, np.newaxis]) + b1\n",
    "    a2 = sigmoide(z2)\n",
    "    z3 = np.dot(W2.T, a2) + b2\n",
    "    y_hat = sigmoide(z3)\n",
    "  \n",
    "    return z2, a2, z3, y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MiOT6jqXjzwQ"
   },
   "source": [
    "Finalmente, definimos la función para entrenar nuestra red neuronal usando gradiente descendente. Para calcular el gradiente de la función de pérdida respecto a los pesos y sesgos en cada capa empleamos el algoritmo de retropropagación.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "1P7i6eLgkJdg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion(X, y, alpha = 0.01, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos = X.shape[0]\n",
    "    n_entradas = X.shape[1]\n",
    "    \n",
    "    # Inicialización de las matrices de pesos W y V\n",
    "    W1 = np.sqrt(1.0 / n_entradas) * np.random.randn(n_entradas, n_ocultas)\n",
    "    b1 = np.zeros((n_ocultas, 1))\n",
    "    \n",
    "    W2 = np.sqrt(1.0 / n_ocultas) * np.random.randn(n_ocultas, 1)\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    perdidas = np.zeros((n_epocas))\n",
    "    exactitudes = np.zeros((n_epocas))\n",
    "    y_predicha = np.zeros((y.shape))\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradiente para W2 por retropropagación\n",
    "            delta3 = (y_hat - y[j]) * derivada_sigmoide(z3) \n",
    "            W2 = W2 - alpha * np.outer(a2, delta3)\n",
    "            b2 = b2 - alpha * delta3\n",
    "\n",
    "            # cálculo de gradiente para W1 por retropropagación\n",
    "            delta2 = np.dot(W2, delta3) * derivada_sigmoide(z2)\n",
    "            W1 = W1 - alpha * np.outer(X[j], delta2)\n",
    "            b1 = b1 - alpha * delta2\n",
    "\n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula la pérdida en la época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
    "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
    "                                                              perdidas[i], \n",
    "                                                              exactitudes[i]))\n",
    "\n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Nau0HWsrkRxg"
   },
   "source": [
    "Para probar nuestra red, generamos los ejemplos correspondientes a la operación XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "8txXZ34GkUAF"
   },
   "outputs": [],
   "source": [
    "# ejemplo (XOR)\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "y = np.array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLT8avfhkYH7"
   },
   "source": [
    "Finalmente, entrenamos nuestra red con estos ejemplos por 200 épocas usando una tasa de aprendizaje $\\alpha = 1.0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "ijKxVwZ3kbyR",
    "outputId": "85e096e7-dfc5-45c0-9e71-b7512775c50f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Pérdida = 3.4737521571212318 Exactitud = 25.0\n",
      "Epoch 1: Pérdida = 3.4621893539983217 Exactitud = 25.0\n",
      "Epoch 2: Pérdida = 3.4638591836303827 Exactitud = 50.0\n",
      "Epoch 3: Pérdida = 3.4667990850901718 Exactitud = 50.0\n",
      "Epoch 4: Pérdida = 3.4692765311295695 Exactitud = 50.0\n",
      "Epoch 5: Pérdida = 3.4712999939289766 Exactitud = 50.0\n",
      "Epoch 6: Pérdida = 3.4730576791773418 Exactitud = 50.0\n",
      "Epoch 7: Pérdida = 3.474680551473296 Exactitud = 50.0\n",
      "Epoch 8: Pérdida = 3.4762395683680385 Exactitud = 50.0\n",
      "Epoch 9: Pérdida = 3.477769475088765 Exactitud = 50.0\n",
      "Epoch 10: Pérdida = 3.479286009088914 Exactitud = 50.0\n",
      "Epoch 11: Pérdida = 3.4807954729134245 Exactitud = 50.0\n",
      "Epoch 12: Pérdida = 3.482299609461905 Exactitud = 50.0\n",
      "Epoch 13: Pérdida = 3.483797989727295 Exactitud = 50.0\n",
      "Epoch 14: Pérdida = 3.485289159117471 Exactitud = 50.0\n",
      "Epoch 15: Pérdida = 3.48677118131892 Exactitud = 50.0\n",
      "Epoch 16: Pérdida = 3.4882418941046383 Exactitud = 50.0\n",
      "Epoch 17: Pérdida = 3.4896990286323075 Exactitud = 50.0\n",
      "Epoch 18: Pérdida = 3.4911402644339606 Exactitud = 50.0\n",
      "Epoch 19: Pérdida = 3.4925632542361824 Exactitud = 50.0\n",
      "Epoch 20: Pérdida = 3.493965634659589 Exactitud = 50.0\n",
      "Epoch 21: Pérdida = 3.495345030303303 Exactitud = 50.0\n",
      "Epoch 22: Pérdida = 3.496699054706433 Exactitud = 50.0\n",
      "Epoch 23: Pérdida = 3.4980253098019345 Exactitud = 50.0\n",
      "Epoch 24: Pérdida = 3.4993213846049835 Exactitud = 50.0\n",
      "Epoch 25: Pérdida = 3.5005848534740958 Exactitud = 25.0\n",
      "Epoch 26: Pérdida = 3.5018132740977728 Exactitud = 25.0\n",
      "Epoch 27: Pérdida = 3.5030041852753726 Exactitud = 25.0\n",
      "Epoch 28: Pérdida = 3.5041551045237114 Exactitud = 25.0\n",
      "Epoch 29: Pérdida = 3.5052635255251907 Exactitud = 25.0\n",
      "Epoch 30: Pérdida = 3.5063269154276524 Exactitud = 25.0\n",
      "Epoch 31: Pérdida = 3.5073427120050207 Exactitud = 25.0\n",
      "Epoch 32: Pérdida = 3.5083083206889745 Exactitud = 25.0\n",
      "Epoch 33: Pérdida = 3.5092211114841056 Exactitud = 25.0\n",
      "Epoch 34: Pérdida = 3.5100784157817615 Exactitud = 25.0\n",
      "Epoch 35: Pérdida = 3.51087752309098 Exactitud = 25.0\n",
      "Epoch 36: Pérdida = 3.511615677708261 Exactitud = 25.0\n",
      "Epoch 37: Pérdida = 3.512290075351479 Exactitud = 25.0\n",
      "Epoch 38: Pérdida = 3.5128978597869422 Exactitud = 25.0\n",
      "Epoch 39: Pérdida = 3.5134361194823702 Exactitud = 25.0\n",
      "Epoch 40: Pérdida = 3.5139018843223697 Exactitud = 25.0\n",
      "Epoch 41: Pérdida = 3.514292122426847 Exactitud = 25.0\n",
      "Epoch 42: Pérdida = 3.5146037371165555 Exactitud = 25.0\n",
      "Epoch 43: Pérdida = 3.514833564073667 Exactitud = 25.0\n",
      "Epoch 44: Pérdida = 3.514978368748766 Exactitud = 25.0\n",
      "Epoch 45: Pérdida = 3.515034844068952 Exactitud = 25.0\n",
      "Epoch 46: Pérdida = 3.5149996085047386 Exactitud = 25.0\n",
      "Epoch 47: Pérdida = 3.5148692045560144 Exactitud = 25.0\n",
      "Epoch 48: Pérdida = 3.514640097719547 Exactitud = 25.0\n",
      "Epoch 49: Pérdida = 3.5143086760020874 Exactitud = 25.0\n",
      "Epoch 50: Pérdida = 3.5138712500442133 Exactitud = 25.0\n",
      "Epoch 51: Pérdida = 3.513324053920366 Exactitud = 25.0\n",
      "Epoch 52: Pérdida = 3.5126632466801126 Exactitud = 25.0\n",
      "Epoch 53: Pérdida = 3.5118849146944426 Exactitud = 25.0\n",
      "Epoch 54: Pérdida = 3.51098507486873 Exactitud = 25.0\n",
      "Epoch 55: Pérdida = 3.5099596787808798 Exactitud = 25.0\n",
      "Epoch 56: Pérdida = 3.5088046177990444 Exactitud = 25.0\n",
      "Epoch 57: Pérdida = 3.507515729228073 Exactitud = 25.0\n",
      "Epoch 58: Pérdida = 3.5060888035275757 Exactitud = 25.0\n",
      "Epoch 59: Pérdida = 3.504519592636994 Exactitud = 25.0\n",
      "Epoch 60: Pérdida = 3.5028038194345226 Exactitud = 25.0\n",
      "Epoch 61: Pérdida = 3.500937188347001 Exactitud = 25.0\n",
      "Epoch 62: Pérdida = 3.498915397116977 Exactitud = 25.0\n",
      "Epoch 63: Pérdida = 3.496734149721266 Exactitud = 25.0\n",
      "Epoch 64: Pérdida = 3.4943891704222536 Exactitud = 25.0\n",
      "Epoch 65: Pérdida = 3.491876218919175 Exactitud = 25.0\n",
      "Epoch 66: Pérdida = 3.4891911065517616 Exactitud = 25.0\n",
      "Epoch 67: Pérdida = 3.4863297134927738 Exactitud = 25.0\n",
      "Epoch 68: Pérdida = 3.4832880068496306 Exactitud = 50.0\n",
      "Epoch 69: Pérdida = 3.4800620595782332 Exactitud = 50.0\n",
      "Epoch 70: Pérdida = 3.4766480700947455 Exactitud = 50.0\n",
      "Epoch 71: Pérdida = 3.4730423824533805 Exactitud = 50.0\n",
      "Epoch 72: Pérdida = 3.4692415069406954 Exactitud = 50.0\n",
      "Epoch 73: Pérdida = 3.46524214091929 Exactitud = 50.0\n",
      "Epoch 74: Pérdida = 3.4610411897369797 Exactitud = 50.0\n",
      "Epoch 75: Pérdida = 3.4566357875012113 Exactitud = 50.0\n",
      "Epoch 76: Pérdida = 3.452023317503306 Exactitud = 50.0\n",
      "Epoch 77: Pérdida = 3.4472014320634736 Exactitud = 50.0\n",
      "Epoch 78: Pérdida = 3.442168071555473 Exactitud = 50.0\n",
      "Epoch 79: Pérdida = 3.4369214823601215 Exactitud = 50.0\n",
      "Epoch 80: Pérdida = 3.431460233489621 Exactitud = 50.0\n",
      "Epoch 81: Pérdida = 3.425783231620567 Exactitud = 50.0\n",
      "Epoch 82: Pérdida = 3.4198897342727905 Exactitud = 50.0\n",
      "Epoch 83: Pérdida = 3.413779360874399 Exactitud = 50.0\n",
      "Epoch 84: Pérdida = 3.40745210146084 Exactitud = 50.0\n",
      "Epoch 85: Pérdida = 3.4009083227678616 Exactitud = 50.0\n",
      "Epoch 86: Pérdida = 3.394148771495265 Exactitud = 50.0\n",
      "Epoch 87: Pérdida = 3.387174574540338 Exactitud = 50.0\n",
      "Epoch 88: Pérdida = 3.379987236027142 Exactitud = 50.0\n",
      "Epoch 89: Pérdida = 3.3725886309901205 Exactitud = 50.0\n",
      "Epoch 90: Pérdida = 3.364980995607721 Exactitud = 50.0\n",
      "Epoch 91: Pérdida = 3.357166913923499 Exactitud = 50.0\n",
      "Epoch 92: Pérdida = 3.349149301037854 Exactitud = 50.0\n",
      "Epoch 93: Pérdida = 3.3409313828024683 Exactitud = 50.0\n",
      "Epoch 94: Pérdida = 3.332516672100709 Exactitud = 50.0\n",
      "Epoch 95: Pérdida = 3.323908941849719 Exactitud = 50.0\n",
      "Epoch 96: Pérdida = 3.315112194912256 Exactitud = 50.0\n",
      "Epoch 97: Pérdida = 3.3061306311575 Exactitud = 50.0\n",
      "Epoch 98: Pérdida = 3.296968611958425 Exactitud = 50.0\n",
      "Epoch 99: Pérdida = 3.2876306224577094 Exactitud = 50.0\n",
      "Epoch 100: Pérdida = 3.278121231973205 Exactitud = 50.0\n",
      "Epoch 101: Pérdida = 3.26844505294651 Exactitud = 50.0\n",
      "Epoch 102: Pérdida = 3.258606698863188 Exactitud = 50.0\n",
      "Epoch 103: Pérdida = 3.24861074158989 Exactitud = 50.0\n",
      "Epoch 104: Pérdida = 3.2384616685815732 Exactitud = 50.0\n",
      "Epoch 105: Pérdida = 3.2281638404108968 Exactitud = 50.0\n",
      "Epoch 106: Pérdida = 3.217721449061877 Exactitud = 50.0\n",
      "Epoch 107: Pérdida = 3.2071384774114104 Exactitud = 50.0\n",
      "Epoch 108: Pérdida = 3.1964186602958717 Exactitud = 50.0\n",
      "Epoch 109: Pérdida = 3.185565447526901 Exactitud = 50.0\n",
      "Epoch 110: Pérdida = 3.1745819691814186 Exactitud = 50.0\n",
      "Epoch 111: Pérdida = 3.163471003447616 Exactitud = 50.0\n",
      "Epoch 112: Pérdida = 3.152234947262055 Exactitud = 50.0\n",
      "Epoch 113: Pérdida = 3.140875789924845 Exactitud = 50.0\n",
      "Epoch 114: Pérdida = 3.1293950898311187 Exactitud = 50.0\n",
      "Epoch 115: Pérdida = 3.117793954409124 Exactitud = 50.0\n",
      "Epoch 116: Pérdida = 3.1060730233091416 Exactitud = 50.0\n",
      "Epoch 117: Pérdida = 3.0942324548438416 Exactitud = 50.0\n",
      "Epoch 118: Pérdida = 3.082271915640349 Exactitud = 50.0\n",
      "Epoch 119: Pérdida = 3.070190573427409 Exactitud = 50.0\n",
      "Epoch 120: Pérdida = 3.0579870928477133 Exactitud = 50.0\n",
      "Epoch 121: Pérdida = 3.0456596341555215 Exactitud = 50.0\n",
      "Epoch 122: Pérdida = 3.033205854632848 Exactitud = 50.0\n",
      "Epoch 123: Pérdida = 3.0206229125330237 Exactitud = 50.0\n",
      "Epoch 124: Pérdida = 3.007907473337794 Exactitud = 50.0\n",
      "Epoch 125: Pérdida = 2.995055718092592 Exactitud = 50.0\n",
      "Epoch 126: Pérdida = 2.982063353563216 Exactitud = 50.0\n",
      "Epoch 127: Pérdida = 2.968925623935632 Exactitud = 50.0\n",
      "Epoch 128: Pérdida = 2.955637323757989 Exactitud = 50.0\n",
      "Epoch 129: Pérdida = 2.9421928118004637 Exactitud = 50.0\n",
      "Epoch 130: Pérdida = 2.9285860254837903 Exactitud = 50.0\n",
      "Epoch 131: Pérdida = 2.9148104955024143 Exactitud = 50.0\n",
      "Epoch 132: Pérdida = 2.90085936024368 Exactitud = 50.0\n",
      "Epoch 133: Pérdida = 2.886725379582435 Exactitud = 50.0\n",
      "Epoch 134: Pérdida = 2.872400947613012 Exactitud = 50.0\n",
      "Epoch 135: Pérdida = 2.8578781038711094 Exactitud = 50.0\n",
      "Epoch 136: Pérdida = 2.8431485426001366 Exactitud = 50.0\n",
      "Epoch 137: Pérdida = 2.8282036196349454 Exactitud = 50.0\n",
      "Epoch 138: Pérdida = 2.813034356515144 Exactitud = 50.0\n",
      "Epoch 139: Pérdida = 2.7976314415059496 Exactitud = 50.0\n",
      "Epoch 140: Pérdida = 2.7819852273018366 Exactitud = 50.0\n",
      "Epoch 141: Pérdida = 2.766085725321928 Exactitud = 50.0\n",
      "Epoch 142: Pérdida = 2.749922596680225 Exactitud = 50.0\n",
      "Epoch 143: Pérdida = 2.733485140130562 Exactitud = 50.0\n",
      "Epoch 144: Pérdida = 2.7167622775465086 Exactitud = 50.0\n",
      "Epoch 145: Pérdida = 2.6997425377978783 Exactitud = 50.0\n",
      "Epoch 146: Pérdida = 2.682414040223185 Exactitud = 50.0\n",
      "Epoch 147: Pérdida = 2.664764479263014 Exactitud = 50.0\n",
      "Epoch 148: Pérdida = 2.6467811122007454 Exactitud = 50.0\n",
      "Epoch 149: Pérdida = 2.6284507523395044 Exactitud = 50.0\n",
      "Epoch 150: Pérdida = 2.609759770309289 Exactitud = 50.0\n",
      "Epoch 151: Pérdida = 2.5906941065256155 Exactitud = 50.0\n",
      "Epoch 152: Pérdida = 2.5712392980886865 Exactitud = 50.0\n",
      "Epoch 153: Pérdida = 2.5513805235977567 Exactitud = 50.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154: Pérdida = 2.531102669437143 Exactitud = 50.0\n",
      "Epoch 155: Pérdida = 2.510390421048062 Exactitud = 50.0\n",
      "Epoch 156: Pérdida = 2.4892283825164983 Exactitud = 50.0\n",
      "Epoch 157: Pérdida = 2.4676012274670835 Exactitud = 50.0\n",
      "Epoch 158: Pérdida = 2.445493883745675 Exactitud = 50.0\n",
      "Epoch 159: Pérdida = 2.422891753691932 Exactitud = 50.0\n",
      "Epoch 160: Pérdida = 2.399780970944671 Exactitud = 50.0\n",
      "Epoch 161: Pérdida = 2.376148693687943 Exactitud = 50.0\n",
      "Epoch 162: Pérdida = 2.351983433039436 Exactitud = 50.0\n",
      "Epoch 163: Pérdida = 2.327275413913871 Exactitud = 50.0\n",
      "Epoch 164: Pérdida = 2.3020169641763677 Exactitud = 50.0\n",
      "Epoch 165: Pérdida = 2.2762029262539674 Exactitud = 50.0\n",
      "Epoch 166: Pérdida = 2.2498310836250646 Exactitud = 50.0\n",
      "Epoch 167: Pérdida = 2.2229025927948394 Exactitud = 50.0\n",
      "Epoch 168: Pérdida = 2.1954224095422985 Exactitud = 50.0\n",
      "Epoch 169: Pérdida = 2.1673996964630735 Exactitud = 50.0\n",
      "Epoch 170: Pérdida = 2.1388481972272437 Exactitud = 50.0\n",
      "Epoch 171: Pérdida = 2.1097865616471063 Exactitud = 50.0\n",
      "Epoch 172: Pérdida = 2.0802386047598347 Exactitud = 50.0\n",
      "Epoch 173: Pérdida = 2.0502334828557642 Exactitud = 75.0\n",
      "Epoch 174: Pérdida = 2.0198057699230376 Exactitud = 75.0\n",
      "Epoch 175: Pérdida = 1.9889954195301716 Exactitud = 75.0\n",
      "Epoch 176: Pérdida = 1.9578475998937412 Exactitud = 75.0\n",
      "Epoch 177: Pérdida = 1.9264123938718294 Exactitud = 100.0\n",
      "Epoch 178: Pérdida = 1.8947443608627044 Exactitud = 100.0\n",
      "Epoch 179: Pérdida = 1.8629019638960904 Exactitud = 100.0\n",
      "Epoch 180: Pérdida = 1.830946872227379 Exactitud = 100.0\n",
      "Epoch 181: Pérdida = 1.7989431569565686 Exactitud = 100.0\n",
      "Epoch 182: Pérdida = 1.766956403936056 Exactitud = 100.0\n",
      "Epoch 183: Pérdida = 1.7350527737955224 Exactitud = 100.0\n",
      "Epoch 184: Pérdida = 1.7032980426456612 Exactitud = 100.0\n",
      "Epoch 185: Pérdida = 1.671756658445274 Exactitud = 100.0\n",
      "Epoch 186: Pérdida = 1.6404908469162431 Exactitud = 100.0\n",
      "Epoch 187: Pérdida = 1.6095597973749924 Exactitud = 100.0\n",
      "Epoch 188: Pérdida = 1.5790189533301349 Exactitud = 100.0\n",
      "Epoch 189: Pérdida = 1.5489194258203414 Exactitud = 100.0\n",
      "Epoch 190: Pérdida = 1.5193075399953384 Exactitud = 100.0\n",
      "Epoch 191: Pérdida = 1.4902245181227625 Exactitud = 100.0\n",
      "Epoch 192: Pérdida = 1.4617062956526776 Exactitud = 100.0\n",
      "Epoch 193: Pérdida = 1.4337834616103096 Exactitud = 100.0\n",
      "Epoch 194: Pérdida = 1.4064813106182434 Exactitud = 100.0\n",
      "Epoch 195: Pérdida = 1.3798199912811666 Exactitud = 100.0\n",
      "Epoch 196: Pérdida = 1.3538147343667295 Exactitud = 100.0\n",
      "Epoch 197: Pérdida = 1.3284761439722486 Exactitud = 100.0\n",
      "Epoch 198: Pérdida = 1.3038105354379719 Exactitud = 100.0\n",
      "Epoch 199: Pérdida = 1.2798203049229717 Exactitud = 100.0\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "W1, W2, perdidas, exactitudes = retropropagacion(X, \n",
    "                                                 y, \n",
    "                                                 alpha = 1.0, \n",
    "                                                 n_epocas = 200,\n",
    "                                                 n_ocultas = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8A3KZ5JkDJ3"
   },
   "source": [
    "Graficamos el valor de la pérdida y la exactitud en cada época para ver el comportamiento de nuestra red durante el entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "yglJSF9nkR7k",
    "outputId": "3339598f-a87a-469b-8499-bc16add9a559"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(perdidas.size), perdidas, label='ECB')\n",
    "plt.plot(np.arange(exactitudes.size), exactitudes, label='Exactitud')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hz0OaZtsCCgs"
   },
   "source": [
    "## Inicializando los pesos con zeros\n",
    "Como se mencionó anteriormente, las matrices de pesos $\\mathbf{W^{\\{1\\}}}$ y $\\mathbf{W^{\\{2\\}}}$ se initializan con valores aleatorios pequeños mientras que los vectores de sesgo $\\mathbf{b^{\\{1\\}}}$ y $\\mathbf{b^{\\{1\\}}}$ con zeros. Examinemos qué pasa si inicializamos las matrices de pesos con zeros. Observa los valores de los pesos en cada época."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "FHaavbWGzqzg"
   },
   "outputs": [],
   "source": [
    "def retropropagacion_zeros(X, y, alpha = 0.1, n_epocas = 100, n_ocultas = 10):\n",
    "    n_ejemplos = X.shape[0]\n",
    "    n_entradas = X.shape[1]\n",
    "    \n",
    "    # Inicializa matrices de pesos W1 y W2 y vectores de sesgos b1 y b2\n",
    "    W1 = np.zeros((n_entradas, n_ocultas))\n",
    "    b1 = np.zeros((n_ocultas, 1)) \n",
    "    W2 = np.zeros((n_ocultas, 1))\n",
    "    b2 = np.zeros((1, 1))\n",
    "    \n",
    "    perdidas = np.zeros((n_epocas))\n",
    "    exactitudes = np.zeros((n_epocas))\n",
    "    y_predicha = np.zeros((y.shape))\n",
    "    for i in range(n_epocas):\n",
    "        for j in range(n_ejemplos):\n",
    "            z2, a2, z3, y_hat = hacia_adelante(X[j], W1, b1, W2, b2)\n",
    "\n",
    "            # cálculo de gradiente para W2 por retropropagación\n",
    "            delta3 = (y[j] - y_hat) * derivada_sigmoide(z3)\n",
    "            W2 = W2 - alpha * np.outer(a2, delta3)\n",
    "            b2 = b2 - alpha * delta3\n",
    "            \n",
    "            # calculo de gradiente para W1 por retropropagación\n",
    "            delta2 = np.dot(W2, delta3) * derivada_sigmoide(z2)\n",
    "            W1 = W1 - alpha * np.outer(X[j], delta2)\n",
    "            b1 = b1 - alpha * delta2\n",
    "            \n",
    "            y_predicha[j] = y_hat\n",
    "            \n",
    "        # calcula la pérdida en época\n",
    "        perdidas[i] = entropia_cruzada_binaria(y, y_predicha)\n",
    "        exactitudes[i] = exactitud(y, np.round(y_predicha))\n",
    "        print('Epoch {0}: Pérdida = {1} Exactitud = {2}'.format(i, \n",
    "                                                              perdidas[i], \n",
    "                                                              exactitudes[i]))\n",
    "        print('W1 = {0}'.format(W1))\n",
    "        print('W2 = {0}'.format(W2))\n",
    "            \n",
    "    return W1, W2, perdidas, exactitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jr1HownICHf9",
    "outputId": "557c44b1-31ad-47e8-e487-10dcbd42672b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: Pérdida = 2.383938269247035 Exactitud = 100.0\n",
      "W1 = [[ 0.0015006   0.0015006   0.0015006   0.0015006   0.0015006   0.0015006\n",
      "   0.0015006   0.0015006   0.0015006   0.0015006 ]\n",
      " [-0.00013937 -0.00013937 -0.00013937 -0.00013937 -0.00013937 -0.00013937\n",
      "  -0.00013937 -0.00013937 -0.00013937 -0.00013937]]\n",
      "W2 = [[0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]\n",
      " [0.00877009]]\n",
      "Epoch 1: Pérdida = 2.3940150790588524 Exactitud = 75.0\n",
      "W1 = [[3.07843345e-03 3.07843345e-03 3.07843345e-03 3.07843345e-03\n",
      "  3.07843345e-03 3.07843345e-03 3.07843345e-03 3.07843345e-03\n",
      "  3.07843345e-03 3.07843345e-03]\n",
      " [6.32326402e-05 6.32326402e-05 6.32326402e-05 6.32326402e-05\n",
      "  6.32326402e-05 6.32326402e-05 6.32326402e-05 6.32326402e-05\n",
      "  6.32326402e-05 6.32326402e-05]]\n",
      "W2 = [[0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]\n",
      " [0.03001629]]\n",
      "Epoch 2: Pérdida = 2.454375736775318 Exactitud = 50.0\n",
      "W1 = [[0.00535668 0.00535668 0.00535668 0.00535668 0.00535668 0.00535668\n",
      "  0.00535668 0.00535668 0.00535668 0.00535668]\n",
      " [0.00153339 0.00153339 0.00153339 0.00153339 0.00153339 0.00153339\n",
      "  0.00153339 0.00153339 0.00153339 0.00153339]]\n",
      "W2 = [[0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]\n",
      " [0.07968444]]\n",
      "Epoch 3: Pérdida = 2.7471355126181987 Exactitud = 50.0\n",
      "W1 = [[0.01036404 0.01036404 0.01036404 0.01036404 0.01036404 0.01036404\n",
      "  0.01036404 0.01036404 0.01036404 0.01036404]\n",
      " [0.00645381 0.00645381 0.00645381 0.00645381 0.00645381 0.00645381\n",
      "  0.00645381 0.00645381 0.00645381 0.00645381]]\n",
      "W2 = [[0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]\n",
      " [0.17472438]]\n",
      "Epoch 4: Pérdida = 3.5902678548185696 Exactitud = 50.0\n",
      "W1 = [[0.01745773 0.01745773 0.01745773 0.01745773 0.01745773 0.01745773\n",
      "  0.01745773 0.01745773 0.01745773 0.01745773]\n",
      " [0.01361346 0.01361346 0.01361346 0.01361346 0.01361346 0.01361346\n",
      "  0.01361346 0.01361346 0.01361346 0.01361346]]\n",
      "W2 = [[0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]\n",
      " [0.28213958]]\n"
     ]
    }
   ],
   "source": [
    "W1, W2, perdidas, exactitudes = retropropagacion_zeros(X, \n",
    "                                                       y, \n",
    "                                                       alpha = 1.0,\n",
    "                                                       n_epocas = 5,\n",
    "                                                       n_ocultas = 10)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "1c_retropropagacion.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
